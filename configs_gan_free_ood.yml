  Introduction : 'GAN-free optimizer on imagenet with resolution 64x64'
  
  optim : "GAN_free"    #optim method
  cost_fn : "sim_cmpr0"   #the type of loss function 
  # cost_fn : "l2"   #the type of loss function 

  indices : "def"      #decide which part of gradients to be involved in the final gradients match loss.
  weights : 'equal'    #weight of every graident scalar's matching loss
  init : 'randn'     #how we initial the original latent code.
  model : "ResNet18"   #FL model
  restarts : 4

  num_images : 1   #How many images we want to reconstruct at a batch
  num_exp : 15
  target_id : 0
  lr : 0.1            #learning rate for Yin et al.
  total_variation : 0.0001     #the coefficient of total variation 
  image_norm : 0.000001    #the coefficient of norm regularizer for Yin et al.
  group_lazy : 0.01    #choose if we use group lazy regularization for Yin et al.
  
  bn_stat : 0       #choose if we use bn statistic to regularizer 

  max_iterations : 15000    #Maximum number of iterations for reconstruction.

  gias_lr : 0.00001   #For biggan, we'd better choose smaller learning rate 
  
  # For input data

  generative_model : 'BigGAN'
  gen_dataset : 'ImageNet64'
  dataset : "OOD_IMAGENET"
  data_path : "./dataset/ood_imagenet/ood_imagenet_ap"

  # dataset : "OOD_FFHQ"
  # data_path : "./dataset/ood_ffhq/ood_ffhq_photo"
  # generative_model : 'stylegan2_io'
  # gen_dataset : 'FFHQ64'

  #For output data
  exp_name : 'ex1_15img_photo_gan_free'   #Same latent space search
  # output_dir : 'solve_ilo_not_ood'
  # output_dir : 'outputs/gan_free/imagenet'
  output_dir : "ood_outputs/photo/ffhq/gan_free"
  #params for inter_optim
  geiping : true
  yin : true

  mae : false
  #Defense parameter
  defense_method : None
  defense_setting : 
      - noise : None
      - clipping : None
      - compression : None
      - representation : None


  # The pre-trained StyleGAN checkpoint
  ckpt: None

  #LR pace for training
  lr_same_pace: false 

  #cmd instruction
  # python rec_mult.py --unsigned --save_image
  